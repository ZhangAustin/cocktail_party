## Multi-Modal Multi-Channel Corpus  

This is an audio-visual dataset with transcriptions, speaker identities and their directional location in the camera. The corpus contains training, dev and evaluation sets. The training set consists of short clips of human speech extracted from [Tencent Video](https://v.qq.com/). The audios in training set were simulated into multi-channel far-field data. The dev and evaluation set consists of multi-channel audios and videos both recorded using our devices which contain a 15-channel microphone array and a 180-degree 4k camera. 

You can use the [editor on GitHub](https://github.com/ZhangAustin/cocktail_party/edit/master/README.md) to maintain and preview the content for your website in Markdown files.


## Cocktail Party Problem

Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files.

Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

```markdown
Syntax highlighted code block

# Training Set
# Evaluation Set
# Data Loader

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

## Multi-Modal Multi-Channel System

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/ZhangAustin/cocktail_party/settings). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

## Publications

Some of our publications related to this corpus can be found below.

* #### Multi-Modal System and Corpus
  *  ###### [1] [Multi-modal Multi-Channel System and Corpus for Cocktail Party Problems (in preparation)]()

* #### Multi-Modal Speaker Diarization
  *  ###### [2] [Multi-modal Multi-Channel Speaker Diarization (in preparation)]()
  *  ###### [3] [Self-supervised Learning for Audio-Visual Speaker Diarization](https://arxiv.org/abs/2002.05314)

* #### Multi-Modal Speech Separation
  *  ###### [3] [Multi-modal Multi-channel Target Speech Separation](https://arxiv.org/abs/2003.07032)
  *  ###### [4] [Time Domain Audio Visual Speech Separation](https://arxiv.org/abs/1904.03760)
  *  ###### [5] [Audio-Visual Speech Separation and Dereverberation with a Two-Stage Multimodal Network](https://arxiv.org/abs/1909.07352)

* #### Multi-Modal Speech Recognition
  *  ###### [7] [Audio-visual Recognition of Overlapped speech for the LRS2 dataset](https://arxiv.org/abs/2001.01656.pdf)

* #### Privacy Preserving (if video privacy is concerned)
  *  ###### [7] [Encrypted Speech Recognition Using Deep Polynomial Networks](https://arxiv.org/abs/1905.05605)

